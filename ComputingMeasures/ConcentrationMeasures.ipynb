{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import jdatetime as jd\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import pickle\n",
    "import io\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# import power_index_calculator as px\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Changing Arbic Characters to Persian Characters !\n",
    "## Credit to \"https://github.com/rezakamalifard/Persian/blob/master/persian/persian.py\"\n",
    "import re\n",
    "def convert_ar_characters(input_str):\n",
    "    mapping = {\n",
    "        'ك': 'ک',\n",
    "        'دِ': 'د',\n",
    "        'بِ': 'ب',\n",
    "        'زِ': 'ز',\n",
    "        'ذِ': 'ذ',\n",
    "        'شِ': 'ش',\n",
    "        'سِ': 'س',\n",
    "        'ى': 'ی',\n",
    "        'ي': 'ی'\n",
    "    }\n",
    "    return _multiple_replace(mapping, input_str)\n",
    "\n",
    "def _multiple_replace(mapping, text):\n",
    "    pattern = \"|\".join(map(re.escape, mapping.keys()))\n",
    "    return re.sub(pattern, lambda m: mapping[m.group()], str(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Loading Balancesheet Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to read different file and prepare them\n",
    "def read_blnc_data(file='98.txt',path=r\"C:\\Users\\Mahdi\\OneDrive\\Master Thesis\\Data\"):\n",
    "\n",
    "    os.chdir(path)\n",
    "    with open(file,encoding=\"utf8\") as f:\n",
    "        fileobject = io.StringIO(f.read())\n",
    "\n",
    "    BlncData = pd.read_csv(fileobject, sep='\\t',  lineterminator='\\n', names=None)\n",
    "    \n",
    "    # Selecting Columns\n",
    "    BlncData = BlncData[['نماد', 'سال مالی', 'تاریخ مصوب','جمع دارایی‌های جاری',\n",
    "           'سرمایه گذاری‌ها و سایر دارایی‌ها', 'خالص دارایی‌های ثابت',\n",
    "           'جمع دارایی‌های غیر جاری', 'جمع کل دارایی‌ها', 'جمع بدهی‌های جاری',\n",
    "           'جمع بدهی‌های غیر جاری', 'جمع کل بدهی‌ها', 'سرمایه',\n",
    "           'سود و زیان انباشته', 'اندوخته قانونی',\n",
    "           'جمع حقوق صاحبان سهام در پایان سال مالی',\n",
    "           'جمع کل بدهی‌ها و حقوق صاحبان سهام',\n",
    "           'جمع حقوق صاحبان سهام مصوب (در مجمع عادی)']]\n",
    "    \n",
    "    # renaming columns\n",
    "    BlncData.rename(columns={'نماد':'Symbol','سال مالی':'Fin_year','جمع دارایی‌های جاری':'Tot_current_asset','تاریخ مصوب':'approve_date',\n",
    "                             'خالص دارایی‌های ثابت':'Net_fixed_assed','سرمایه گذاری‌ها و سایر دارایی‌ها':'other_asset',\n",
    "                             'جمع بدهی‌های جاری':'Tot_current_lib','جمع کل دارایی‌ها':'Tot_asset','جمع دارایی‌های غیر جاری':'Tot_uncurrent_asset',\n",
    "                             'سرمایه':'Capital','حقوق عمومی':'Public_rights','جمع کل بدهی‌ها':'Tot_lib','جمع بدهی‌های غیر جاری':'Tot_uncurrent_lib',\n",
    "                             'سایر اندوخته‌ها':'Other_saving','اندوخته قانونی':'Reserved_saving','سود و زیان انباشته':'Comulated_profit_loss',\n",
    "                             'جمع حقوق صاحبان سهام در پایان سال مالی':'Equity_at_year_end','جمع کل بدهی‌ها و حقوق صاحبان سهام':'Debt_Equity',\n",
    "                              'جمع حقوق صاحبان سهام مصوب (در مجمع عادی)':'Debt_Equity_normal'},inplace=True)\n",
    "\n",
    "    # DataOrg.Symbol: convert_ar_characters(x)\n",
    "    Names = BlncData.Symbol.drop_duplicates()\n",
    "    Conv_Names = Names.apply(lambda x : convert_ar_characters(x))\n",
    "    BlncData_Symbol_ArtoFa_dict = dict(zip(Names,Conv_Names))\n",
    "    BlncData['Symbol'] = BlncData.Symbol.map(BlncData_Symbol_ArtoFa_dict)\n",
    "\n",
    "    # Dates\n",
    "    BlncData = BlncData[~pd.isnull(BlncData.Fin_year)]\n",
    "    BlncData.Fin_year = BlncData.Fin_year.apply(lambda x: jd.date(day=int(x[8:10]), month=int(x[5:7]),year=int(x[0:4])))\n",
    "\n",
    "    BlncData = BlncData[~pd.isnull(BlncData.approve_date)]\n",
    "    BlncData.approve_date = BlncData.approve_date.apply(lambda x: jd.date(day=int(x[8:10]), month=int(x[5:7]),year=int(x[0:4])))\n",
    "    \n",
    "    # changing to int\n",
    "    for x in BlncData.columns[3:]:\n",
    "        BlncData = BlncData[~pd.isnull(BlncData[x])]\n",
    "        BlncData[x] = BlncData[x].apply(lambda x: int(x.replace(',','')))\n",
    "        \n",
    "    return(BlncData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "blnc_data = read_blnc_data(file='98.txt')\n",
    "blnc_data['book_value'] = blnc_data.Tot_asset-blnc_data.Tot_lib\n",
    "blnc_data = blnc_data[blnc_data.book_value>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Loading Shareholder Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading DATA\n",
    "os.chdir(r\"C:\\Users\\Mahdi\\OneDrive\\Master Thesis\\Data\")\n",
    "SDATA = pd.read_csv(\"Shareholder97.csv\",index_col=0)\n",
    "\n",
    "# Conver date from string to jdatetime\n",
    "SDATA['True_Date'] = pd.to_datetime(SDATA['True_Date'], format='%Y-%m-%d')\n",
    "G = SDATA.True_Date.drop_duplicates()\n",
    "J = G.apply(lambda x: jd.date.fromgregorian(day=x.day,month=x.month,year=x.year))\n",
    "DataOrg_date_GtoJ_dict = dict(zip(G,J))\n",
    "SDATA['Jalali_Date']=SDATA.True_Date.map(DataOrg_date_GtoJ_dict)\n",
    "\n",
    "SDATA.drop(columns=['High', 'Low', 'Open', 'Last', 'Volume', 'close',\n",
    "       'True_Date', 'year', 'month', 'day', 'Fill_Flag','Unadjusted_close','chnk_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering and keeping symbols that we have data in both datasets\n",
    "sym_list = list(set(blnc_data.Symbol).intersection(set(SDATA.Symbol.drop_duplicates())))\n",
    "SDATA = SDATA[SDATA.Symbol.isin(sym_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Dataframe for saving concentration mearsurs\n",
    "CMdf = SDATA.groupby('Symbol',as_index=False).agg({'Id_tse':'first','percent':'sum','ShareHolder':'count'}).rename(columns={'ShareHolder':'Num_holders','percent':'sum_over1'})\n",
    "CMdf.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Concentration Measures**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Largest Owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = SDATA.groupby('Symbol',as_index=False).agg({'percent':'max'}).rename(columns={'percent':'Largest_Owner'})\n",
    "CMdf = pd.merge(CMdf,temp,left_on='Symbol',right_on='Symbol',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- First/Second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nth_max(data,nth=1,interval=False):\n",
    "    data = data.sort_values(ascending=False)\n",
    "    if interval:\n",
    "        return(np.round(data.iloc[min(nth[0]-1,len(data)-1):min(nth[1],len(data))],2))\n",
    "    else:\n",
    "        return(np.round(data.iloc[min(nth-1,len(data)-1)],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = SDATA.groupby('Symbol',as_index=False).agg({'percent':{lambda x: max(x)/nth_max(x,nth=2,interval=False)}}).rename(columns={'percent':'First_Second'})\n",
    "CMdf = pd.merge(CMdf,temp,left_on='Symbol',right_on='Symbol',how='left').rename(columns={('First_Second', '<lambda>'):'First_Second'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- First/Sumtwofour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = SDATA.groupby('Symbol',as_index=False).agg({'percent':{lambda x: max(x)/sum(nth_max(x,nth=[2,4],interval=True))}}).rename(columns={'percent':'First_Sumtwofour'})\n",
    "CMdf = pd.merge(CMdf,temp,left_on='Symbol',right_on='Symbol',how='left').rename(columns={('First_Sumtwofour', '<lambda>'):'First_Sumtwofour'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Sumfive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = SDATA.groupby('Symbol',as_index=False).agg({'percent':{lambda x: sum(nth_max(x,nth=[1,5],interval=True))/100}}).rename(columns={'percent':'Sumfive'})\n",
    "CMdf = pd.merge(CMdf,temp,left_on='Symbol',right_on='Symbol',how='left').rename(columns={('Sumfive', '<lambda>'):'Sumfive'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- Gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate gini coeficient using Deaton 1997:\n",
    "$$ \\gamma = \\frac{N+1}{N-1} - \\frac{2}{\\mu\\times N\\times(N-1)}\\sum_{i=1}^N{\\rho_ix_i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(data):\n",
    "    data.sort(reverse = True)\n",
    "    N = len(data)\n",
    "    mu = np.mean(data)\n",
    "    ser = [(i+1)*data[i] for i in range(len(data))]\n",
    "    try:\n",
    "        gamma = (N+1)/(N-1)-(2*sum(ser))/(mu*N*(N-1))\n",
    "    except:\n",
    "        gamma = 0\n",
    "    return(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = SDATA.groupby('Symbol',as_index=False).agg({'percent':{lambda x: gini(list(x))}}).rename(columns={'percent':'Gini'})\n",
    "CMdf = pd.merge(CMdf,temp,left_on='Symbol',right_on='Symbol',how='left').rename(columns={('Gini', '<lambda>'):'Gini'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6- Herfindhal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = SDATA.groupby('Symbol',as_index=False).agg({'percent':{lambda x: sum([(t/100)**2 for t in list(x)])}}).rename(columns={'percent':'Herfindhal'})\n",
    "CMdf = pd.merge(CMdf,temp,left_on='Symbol',right_on='Symbol',how='left').rename(columns={('Herfindhal', '<lambda>'):'Herfindhal'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapley-Shubik and Banzhaf Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL Dict\n",
    "URL_shapley={'direct':\"https://mywebpages.csv.warwick.ac.uk/cgi-vpi/ssdirect.cgi\",\n",
    "             'genf':\"https://mywebpages.csv.warwick.ac.uk/cgi-vpi/ssgenf.cgi\",\n",
    "             'mmle':\"https://mywebpages.csv.warwick.ac.uk/cgi-vpi/ssmmle.cgi\",\n",
    "             'ocean':\"https://mywebpages.csv.warwick.ac.uk/cgi-vpi/ssocean.cgi\"}\n",
    "\n",
    "\n",
    "def find_shapley(percent,how='direct',quota = 50.01,major_mode='number',major_thr=20,concentration_point=0.99,time_pnt=False,fast_mode = True):\n",
    "    \n",
    "    \"\"\"\n",
    "    A function for finding Shapley-Shbik Index.\n",
    "    \n",
    "    This functions uses David Leech website to calculate Shapley-Shubik index.\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    percent: list, voting rights\n",
    "    \n",
    "    how: str, 'direct', 'concentrated', 'ocean', 'genf', and 'mmle'\n",
    "    \n",
    "    quota: float\n",
    "    \n",
    "    major_mode: 'percent' or 'number'\n",
    "    \n",
    "    major_thr: if major_mode is 'percnet'--> float\n",
    "               if major_mode is 'number'--> int\n",
    "            \n",
    "    concentration_point: float, [less than 1]\n",
    "    \"\"\"\n",
    "    df = percent\n",
    "    \n",
    "    # sorting\n",
    "    percent.sort(reverse=True)\n",
    "    \n",
    "    # Fast mode calculates\n",
    "    if percent[0]>=quota and fast_mode:\n",
    "        if how is not 'ocean':\n",
    "            out = pd.DataFrame(data={'Weight':percent,\n",
    "                             'SSINDEX':[1]+[0]*(len(percent)-1)})\n",
    "        elif how is 'ocean':\n",
    "            out = pd.DataFrame(data={'Weight':percent+['Ocean'],\n",
    "                             'SSINDEX':[1]+[0]*(len(percent))})\n",
    "\n",
    "        return(out)\n",
    "    \n",
    "    # Checking size of input\n",
    "    if len(df)<=1 and how is not 'ocean' and how is not 'concentrated':\n",
    "        return('Error: Length Error!')\n",
    "    \n",
    "    \n",
    "    ## Preparing website inputs\n",
    "    if how is 'direct':\n",
    "        prc = percent\n",
    "        prc_str = ''\n",
    "        for x in prc:\n",
    "            prc_str+=str(x)\n",
    "            prc_str+=' '\n",
    "        payload = {'numberofplayers': len(df),\n",
    "                   'quota': quota,\n",
    "                   'textarea': prc_str}\n",
    "        \n",
    "        \n",
    "    elif how is 'genf':\n",
    "        prc = [int(x*100)for x in percent]\n",
    "        prc_str = ''\n",
    "        for x in prc:\n",
    "            prc_str+=str(x)\n",
    "            prc_str+=' '\n",
    "        payload = {'numberofplayers': len(df),\n",
    "                   'quota': int(quota*100),\n",
    "                   'textarea': prc_str}    \n",
    "        \n",
    "        \n",
    "    elif how is 'mmle':\n",
    "        prc = [x for x in percent]\n",
    "        prc_str = ''\n",
    "        for x in prc:\n",
    "            prc_str+=str(x)\n",
    "            prc_str+=' '\n",
    "        if major_mode=='percent':\n",
    "            Majors = len([x for x in prc if x>=major_thr])\n",
    "            Minors = len(df) - Majors\n",
    "        elif major_mode=='number':\n",
    "            Majors = len(prc[0:min(major_thr,len(prc))])\n",
    "            Minors = len(prc) - Majors\n",
    "        payload = {'numberofplayers': Majors,#majo3\n",
    "                   'numberofplayers2': Minors,#minor\n",
    "                   'quota': quota,\n",
    "                   'textarea': prc_str}           \n",
    "    \n",
    "    \n",
    "    elif how is 'ocean':\n",
    "        prc = [x for x in percent]\n",
    "        prc_str = ''\n",
    "        for x in prc:\n",
    "            prc_str+=str(x)\n",
    "            prc_str+=' '\n",
    "        total_weight = 100\n",
    "        payload = {'numberofplayers': len(df),# number of atomic players\n",
    "                   'totalweight': total_weight,\n",
    "                   'quota': 50.1,\n",
    "                   'textarea': prc_str}\n",
    "    \n",
    "    \n",
    "    # website url\n",
    "    url = URL_shapley[how]\n",
    "    \n",
    "    # Making request\n",
    "    try:\n",
    "        response = requests.request(\"POST\", url, data = payload)\n",
    "    except:\n",
    "        return('Error: request error!')\n",
    "    if time_pnt:\n",
    "        print(' It took about ',np.round(response.elapsed.microseconds/1e6,2), 'seconds')\n",
    "        \n",
    "    # Parshing output html of wevsite\n",
    "    parsed_html = BeautifulSoup(response.text.encode('utf8'))\n",
    "    \n",
    "     # Finding rows or error message\n",
    "    if parsed_html('tr'):\n",
    "        rows = parsed_html('tr')\n",
    "    else:\n",
    "        return('Error: '+parsed_html.find('p').text)\n",
    "    \n",
    "    # Extracting rows to a list of lists\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        if row.th:\n",
    "            cols = row.find_all('th')\n",
    "            cols = [ele.text.strip() for ele in cols]\n",
    "            if len(cols) is 1:\n",
    "                data.append([cols[0],''])\n",
    "            else:\n",
    "                data.append([ele for ele in cols if ele]) # Get rid of empty valuespty values\n",
    "        else:\n",
    "            cols = row.find_all('td')\n",
    "            cols = [ele.text.strip() for ele in cols]\n",
    "            data.append([ele for ele in cols if ele]) # Get rid of empty values\n",
    "    \n",
    "    # Converting list of lists to a dataframe\n",
    "    try:\n",
    "        if how is 'mmle':\n",
    "            out = pd.DataFrame(data[1:(len(data)-1)], columns=data[0])\n",
    "            out.iloc[:,0] = prc\n",
    "            \n",
    "        elif how is 'ocean':\n",
    "            del data[0]\n",
    "            del data[-2]\n",
    "            data[-1][0] = 'Ocean'\n",
    "            out = pd.DataFrame(data[1:len(data)], columns=data[0])\n",
    "            \n",
    "        else: \n",
    "            out = pd.DataFrame(data[1:], columns=data[0])\n",
    "            out.iloc[:,0] = prc\n",
    "        \n",
    "        out.rename(columns={'Shapley-Shubik Index':'SSINDEX','SHAPLEY-SHUBIK':'SSINDEX','WEIGHT':'Weight'},inplace=True)\n",
    "        return(out)\n",
    "    \n",
    "    except:\n",
    "        return('Error: creating dataFrame error! ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL Dict\n",
    "URL_banzhaf={'direct':\"https://mywebpages.csv.warwick.ac.uk/cgi-vpi/ipdirect.cgi\",\n",
    "             'genf':\"https://mywebpages.csv.warwick.ac.uk/cgi-vpi/ipgenf.cgi\",\n",
    "             'mmle':\"https://mywebpages.csv.warwick.ac.uk/cgi-vpi/ipmmle.cgi\"}\n",
    "\n",
    "\n",
    "def find_banzhaf(percent,how='direct',quota = 50.01,major_mode='number',major_thr=20,concentration_point=0.99,time_pnt=False,fast_mode = True):\n",
    "    \n",
    "    \"\"\"\n",
    "    A function for finding banzhaf Index.\n",
    "    \n",
    "    This functions uses David Leech website to calculate banzhaf index.\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    percent: list, voting rights\n",
    "    \n",
    "    how: str, 'direct', 'concentrated', 'ocean', 'genf', and 'mmle'\n",
    "    \n",
    "    quota: float\n",
    "    \n",
    "    major_mode: 'percent' or 'number'\n",
    "    \n",
    "    major_thr: if major_mode is 'percnet'--> float\n",
    "               if major_mode is 'number'--> int\n",
    "            \n",
    "    concentration_point: float, [less than 1]\n",
    "    \"\"\"\n",
    "    df = percent\n",
    "    \n",
    "    # sorting\n",
    "    percent.sort(reverse=True)\n",
    "    \n",
    "    # Fast mode calculates\n",
    "    if percent[0]>=quota and fast_mode:\n",
    "        out = pd.DataFrame(data={'Weight':percent,\n",
    "                                 'Abs_Banzhaf':[1]+[0]*(len(percent)-1),\n",
    "                                 'Norm_Banzhaf':[1]+[0]*(len(percent)-1),\n",
    "                                 'Coleman_Prevent':[1]+[0]*(len(percent)-1),\n",
    "                                 'Coleman_Initiate':[1]+[0]*(len(percent)-1)})\n",
    "        return(out)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Checking size of input\n",
    "    if len(df)<=1 and how is not 'concentrated':\n",
    "        return('Error: Length Error!')\n",
    "    \n",
    "    \n",
    "    ## Preparing website inputs\n",
    "    if how is 'direct':\n",
    "        prc = percent\n",
    "        prc_str = ''\n",
    "        for x in prc:\n",
    "            prc_str+=str(x)\n",
    "            prc_str+=' '\n",
    "        payload = {'numberofplayers': len(df),\n",
    "                   'quota': quota,\n",
    "                   'textarea': prc_str}\n",
    "        \n",
    "        \n",
    "    elif how is 'genf':\n",
    "        prc = [int(x*100)for x in percent]\n",
    "        prc_str = ''\n",
    "        for x in prc:\n",
    "            prc_str+=str(x)\n",
    "            prc_str+=' '\n",
    "        payload = {'numberofplayers': len(df),\n",
    "                   'quota': int(quota*100),\n",
    "                   'textarea': prc_str}    \n",
    "        \n",
    "        \n",
    "    elif how is 'mmle':\n",
    "        prc = [x for x in percent]\n",
    "        prc_str = ''\n",
    "        for x in prc:\n",
    "            prc_str+=str(x)\n",
    "            prc_str+=' '\n",
    "        if major_mode=='percent':\n",
    "            Majors = len([x for x in prc if x>=major_thr])\n",
    "            Minors = len(prc) - Majors\n",
    "        elif major_mode=='number':\n",
    "            Majors = len(prc[0:min(major_thr,len(prc))])\n",
    "            Minors = len(prc) - Majors\n",
    "        payload = {'numberofplayers': Majors,#majo3\n",
    "                   'numberofplayers2': Minors,#minor\n",
    "                   'quota': quota,\n",
    "                   'textarea': prc_str}           \n",
    "    \n",
    "    \n",
    "    # website url\n",
    "    url = URL_banzhaf[how]\n",
    "    \n",
    "    # Making request\n",
    "    try:\n",
    "        response = requests.request(\"POST\", url, data = payload)\n",
    "    except:\n",
    "        return('Error: request error!')\n",
    "    if time_pnt:\n",
    "        print('It took about ',np.round(response.elapsed.microseconds/1000000,2), 'seconds')\n",
    "        \n",
    "    # Parshing output html of wevsite\n",
    "    parsed_html = BeautifulSoup(response.text.encode('utf8'))\n",
    "    \n",
    "     # Finding rows or error message\n",
    "    if parsed_html('tr'):\n",
    "        rows = parsed_html('tr')\n",
    "    else:\n",
    "        return('Error: '+parsed_html.find('p').text)\n",
    "    \n",
    "    # Extracting rows to a list of lists\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        if row.th:\n",
    "            cols = row.find_all('th')\n",
    "            cols = [ele.text.strip() for ele in cols]\n",
    "            if len(cols) is 1:\n",
    "                data.append([cols[0],''])\n",
    "            else:\n",
    "                data.append([ele for ele in cols if ele]) # Get rid of empty valuespty values\n",
    "        else:\n",
    "            cols = row.find_all('td')\n",
    "            cols = [ele.text.strip() for ele in cols]\n",
    "            data.append([ele for ele in cols if ele]) # Get rid of empty values\n",
    "    \n",
    "    # Converting list of lists to a dataframe\n",
    "    try:\n",
    "        out = pd.DataFrame(data[1:], columns=data[0])\n",
    "        out.iloc[:,0] = prc        \n",
    "        out.rename(columns={'Absolute Banzhaf Index \\n\\n(Penrose Index)':'Abs_Banzhaf',\n",
    "                            'Normalised Banzhaf Index':'Norm_Banzhaf',\n",
    "                            'Coleman\\'s\\nPower to Prevent Action':'Coleman_Prevent',\n",
    "                            'Coleman\\'s Power to Initiate Action':'Coleman_Initiate',\n",
    "                            'WEIGHT':'Weight','weight':'Weight'},inplace=True)\n",
    "        return(out)\n",
    "    \n",
    "    except:\n",
    "        return('Error: creating dataFrame error! ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gameTheoric_concentration(symbol, index='shapley', how='concentrated',quota = 50.01,major_mode='number',major_thr=20,\n",
    "                              concentration_point=0.99,time_pnt=False,fast_mode = True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns index for largest and ocean shareholder!\n",
    "    \"\"\"\n",
    "    \n",
    "    # Chcking inputs\n",
    "    if how not in ['dispersed','concentrated']:\n",
    "        raise ValueError('how must be in [\\'dispersed\\',\\'concentrated\\']!')\n",
    "        \n",
    "    if index not in ['shapley','banzhaf']:\n",
    "        raise ValueError('indes must be in [\\'shapley\\',\\'banzhaf\\']!')\n",
    "    \n",
    "    # List of percents\n",
    "    percent_list = list(SDATA.percent[SDATA.Symbol==symbol])\n",
    "    \n",
    "    # Finding functions\n",
    "    func = {'shapley':find_shapley,'banzhaf':find_banzhaf}[index]\n",
    "    \n",
    "    # Finding results\n",
    "    if how is 'concentrated':\n",
    "        prc = [x for x in percent_list]\n",
    "        unassigned = 100 - sum(prc)\n",
    "        cons_point = concentration_point\n",
    "        number = int(np.floor(unassigned/cons_point))\n",
    "        residual = np.round(unassigned - number*cons_point,2)\n",
    "        percent_list = prc+[cons_point]*number+[residual]    \n",
    "        \n",
    "        if len(percent_list)<15:\n",
    "            results = func(percent=percent_list,how='direct',quota = quota,major_mode=major_mode,\n",
    "                            major_thr=major_thr,concentration_point=concentration_point,time_pnt=time_pnt,fast_mode = fast_mode)\n",
    "        \n",
    "        if len(percent_list)>=15 or isinstance(results,str):\n",
    "            results = func(percent=percent_list,how='mmle',quota = quota,major_mode=major_mode,\n",
    "                            major_thr=major_thr,concentration_point=concentration_point,time_pnt=time_pnt,fast_mode = fast_mode)\n",
    "    \n",
    "    \n",
    "    elif how is 'dispersed' and index is 'shapley':\n",
    "        results = func(percent=percent_list,how='ocean',quota = quota,major_mode=major_mode,\n",
    "                            major_thr=major_thr,concentration_point=concentration_point,time_pnt=time_pnt,fast_mode = fast_mode)\n",
    "    \n",
    "    elif how is 'dispersed' and index is 'banzhaf':\n",
    "        updated_quota = quota - (100-sum(percent_list))/2\n",
    "        if len(percent_list)<15:\n",
    "            results = func(percent=percent_list,how='direct',quota = updated_quota,major_mode=major_mode,\n",
    "                            major_thr=major_thr,concentration_point=concentration_point,time_pnt=time_pnt,fast_mode = fast_mode)\n",
    "        if len(percent_list)>=15 or isinstance(results,str):\n",
    "            results = func(percent=percent_list,how='mmle',quota = updated_quota,major_mode=major_mode,\n",
    "                            major_thr=major_thr,concentration_point=concentration_point,time_pnt=time_pnt,fast_mode = fast_mode)\n",
    "    \n",
    "\n",
    "    \n",
    "    ## Returning output\n",
    "    if index is 'shapley' and np.logical_not(isinstance(results,str)):\n",
    "        if how is 'concentrated':\n",
    "            return([float(results.iloc[0,1]),\n",
    "                   sum(results[results.Weight<=concentration_point]['SSINDEX'].apply(lambda x: float(x)))])\n",
    "        elif how is 'dispersed':\n",
    "            return([float(results.iloc[0,1]),\n",
    "                   float(results[results.Weight=='Ocean']['SSINDEX'])])\n",
    "            \n",
    "    elif index is 'banzhaf' and np.logical_not(isinstance(results,str)):\n",
    "        if how is 'concentrated':\n",
    "            return([float(results.iloc[0,2]),\n",
    "                   sum(results[results.Weight<=concentration_point]['Norm_Banzhaf'].apply(lambda x: float(x)))])\n",
    "        elif how is 'dispersed':\n",
    "            return([float(results.iloc[0,2]),\n",
    "                   np.nan])\n",
    "    else:\n",
    "        return(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 & 8-Shapley-Shubik & Banzhaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating columns\n",
    "CMdf['SSCL'] = np.nan\n",
    "CMdf['SSCO'] = np.nan\n",
    "CMdf['SSDL'] = np.nan\n",
    "CMdf['SSDO'] = np.nan\n",
    "CMdf['BZCL'] = np.nan\n",
    "CMdf['BZCO'] = np.nan\n",
    "CMdf['BZDL'] = np.nan\n",
    "\n",
    "\n",
    "os.chdir(r\"C:\\Users\\Mahdi\\OneDrive\\Master Thesis\\Data\")\n",
    "CMdf = pd.read_csv('Measures.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_shapley_banzhaf(data = CMdf,fast_mode = True,time_pnt=False):\n",
    "    \n",
    "    # list initiation\n",
    "    Errors = []\n",
    "    fatal_error = []\n",
    "    \n",
    "    # Columns to check\n",
    "    check_data = data[['Symbol','SSCL','SSDL','BZCL','BZDL']]\n",
    "    \n",
    "    # Finding location of NaN to fill\n",
    "    indx, col = np.where(pd.isnull(check_data))\n",
    "    ITEMS = [list(x) for x in np.column_stack([check_data.index[indx], check_data.columns[col]])]\n",
    "    lng_0 = len(ITEMS)\n",
    "    \n",
    "    # setting function based on the column name\n",
    "    guide_dict = {'SS':'shapley','BZ':'banzhaf','C':'concentrated','D':'dispersed'}\n",
    "    col_dict = {'SSCL':['SSCL','SSCO'],'SSDL':['SSDL','SSDO'],'BZCL':['BZCL','BZCO'],'BZDL':['BZDL']}\n",
    "    \n",
    "    cnt = 1\n",
    "    for item in ITEMS:\n",
    "        # Assigning addres\n",
    "        index, mode = item\n",
    "        sym = data.Symbol.iloc[index]\n",
    "        \n",
    "        # Progress output\n",
    "        print('The symbol ',sym, ' mode: ',mode,', ',cnt,' from ', len(ITEMS))\n",
    "        cnt+=1 \n",
    "        \n",
    "        # Finding and assigning  value\n",
    "        try:\n",
    "            temp = gameTheoric_concentration(sym, index=guide_dict[mode[0:2]], how=guide_dict[mode[2]],quota = 50.01,major_mode='number',major_thr=20,\n",
    "                                  concentration_point=0.99,time_pnt=time_pnt,fast_mode = fast_mode)\n",
    "            \n",
    "            col_names = col_dict[mode]\n",
    "            data.loc[data.Symbol==sym,col_names[0]] = temp[0]\n",
    "            \n",
    "            # This try handles the BZDO case!\n",
    "            try:\n",
    "                data.loc[data.Symbol==sym,col_names[1]] = temp[1]\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            if isinstance(temp,str):\n",
    "                Errors.append([sym,mode,temp])\n",
    "                data.loc[data.Symbol==sym,col_names[0]] = np.nan\n",
    "                try:\n",
    "                    data.loc[data.Symbol==sym,col_names[1]] = np.nan\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        except:\n",
    "                fatal_error.append([sym,mode])\n",
    "                data.loc[data.Symbol==sym,col_names[0]] = np.nan\n",
    "                try:\n",
    "                    data.loc[data.Symbol==sym,col_names[1]] = np.nan\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                \n",
    "                \n",
    "     \n",
    "    # Columns to check\n",
    "    check_data = data[['Symbol','SSCL','SSDL','BZCL','BZDL']]\n",
    "    \n",
    "    # Finding location of NaN to fill\n",
    "    indx, col = np.where(pd.isnull(check_data))\n",
    "    ITEMS = [list(x) for x in np.column_stack([check_data.index[indx], check_data.columns[col]])]\n",
    "    lng_1 = len(ITEMS)\n",
    "    \n",
    "    print('\\n\\n**About ',lng_0-lng_1,' out of ',lng_0,' of mising cells are filled!')\n",
    "    \n",
    "    \n",
    "    OUT = {'CMdf':data,'fatal_error':fatal_error,'Errors':Errors}\n",
    "    return(OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The symbol  آریان  mode:  SSCL ,  1  from  225\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = fill_shapley_banzhaf(data = CMdf,fast_mode = True,time_pnt=True)\n",
    "CMdf = data['CMdf']\n",
    "\n",
    "os.chdir(r\"C:\\Users\\Mahdi\\OneDrive\\Master Thesis\\Data\")\n",
    "CMdf.to_csv('Measures.csv')\n",
    "\n",
    "print('len(fatal_error): ',len(data['fatal_error']))\n",
    "print('len(Errors): ',len(data['Errors']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[['آریان', 'SSCL', 'Error: request error!'],\n",
       " ['آریان', 'SSDL', 'Error: request error!'],\n",
       " ['بمیلا', 'SSCL', 'Error: request error!'],\n",
       " ['بمیلا', 'BZCL', 'Error: request error!'],\n",
       " ['بنیرو', 'SSCL', 'Error: request error!'],\n",
       " ['بورس', 'SSCL', 'Error: request error!'],\n",
       " ['بورس', 'BZCL', 'Error: request error!'],\n",
       " ['بکاب', 'SSCL', 'Error: request error!'],\n",
       " ['تابا', 'SSCL', 'Error: request error!'],\n",
       " ['تابا', 'BZCL', 'Error: request error!'],\n",
       " ['تایرا', 'SSCL', 'Error: request error!'],\n",
       " ['تایرا', 'BZCL', 'Error: request error!'],\n",
       " ['تمحرکه', 'SSCL', 'Error: request error!'],\n",
       " ['تمحرکه', 'BZCL', 'Error: request error!'],\n",
       " ['توریل', 'SSCL', 'Error: request error!'],\n",
       " ['تپمپی', 'SSCL', 'Error: request error!'],\n",
       " ['تکنو', 'SSCL', 'Error: request error!'],\n",
       " ['تکنو', 'BZCL', 'Error: request error!'],\n",
       " ['ثاصفا', 'SSCL', 'Error: request error!'],\n",
       " ['ثاصفا', 'SSDL', 'Error: request error!'],\n",
       " ['ثاصفا', 'BZCL', 'Error: request error!'],\n",
       " ['ثامان', 'SSCL', 'Error: request error!'],\n",
       " ['ثامان', 'SSDL', 'Error: request error!'],\n",
       " ['ثامان', 'BZCL', 'Error: request error!'],\n",
       " ['ثباغ', 'SSCL', 'Error: request error!'],\n",
       " ['ثباغ', 'SSDL', 'Error: request error!'],\n",
       " ['ثباغ', 'BZCL', 'Error: request error!'],\n",
       " ['ثزاگرس', 'SSCL', 'Error: request error!'],\n",
       " ['ثزاگرس', 'SSDL', 'Error: request error!'],\n",
       " ['ثزاگرس', 'BZCL', 'Error: request error!'],\n",
       " ['ثزاگرس', 'BZDL', 'Error: request error!'],\n",
       " ['ثعتما', 'SSCL', 'Error: request error!'],\n",
       " ['ثعتما', 'BZCL', 'Error: request error!'],\n",
       " ['ثفارس', 'SSCL', 'Error: request error!'],\n",
       " ['ثقزوی', 'SSCL', 'Error: request error!'],\n",
       " ['ثقزوی', 'BZCL', 'Error: request error!'],\n",
       " ['ثمسکن', 'SSCL', 'Error: request error!'],\n",
       " ['ثنظام', 'SSCL', 'Error: request error!'],\n",
       " ['ثنظام', 'BZCL', 'Error: request error!'],\n",
       " ['جم', 'SSCL', 'Error: request error!'],\n",
       " ['حسینا', 'SSCL', 'Error: request error!'],\n",
       " ['حسینا', 'SSDL', 'Error: request error!'],\n",
       " ['حسینا', 'BZCL', 'Error: request error!'],\n",
       " ['حکشتی', 'SSCL', 'Error: request error!'],\n",
       " ['حکشتی', 'SSDL', 'Error: request error!'],\n",
       " ['حکشتی', 'BZCL', 'Error: request error!'],\n",
       " ['حکشتی', 'BZDL', 'Error: request error!'],\n",
       " ['خعمرا', 'SSCL', 'Error: request error!'],\n",
       " ['خفناور', 'SSCL', 'Error: request error!'],\n",
       " ['خفناور', 'BZCL', 'Error: request error!'],\n",
       " ['خنصیر', 'SSCL', 'Error: request error!'],\n",
       " ['خنصیر', 'SSDL', 'Error: request error!'],\n",
       " ['خنصیر', 'BZCL', 'Error: request error!'],\n",
       " ['خکار', 'SSCL', 'Error: request error!'],\n",
       " ['خکار', 'SSDL', 'Error: request error!'],\n",
       " ['خکار', 'BZCL', 'Error: request error!'],\n",
       " ['دحاوی', 'SSCL', 'Error: request error!'],\n",
       " ['دحاوی', 'SSDL', 'Error: request error!'],\n",
       " ['دحاوی', 'BZCL', 'Error: request error!'],\n",
       " ['دحاوی', 'BZDL', 'Error: request error!'],\n",
       " ['ددام', 'SSCL', 'Error: request error!'],\n",
       " ['ددام', 'SSDL', 'Error: request error!'],\n",
       " ['ددام', 'BZCL', 'Error: request error!'],\n",
       " ['دروز', 'SSCL', 'Error: request error!'],\n",
       " ['دروز', 'SSDL', 'Error: request error!'],\n",
       " ['دروز', 'BZCL', 'Error: request error!'],\n",
       " ['دروز', 'BZDL', 'Error: request error!'],\n",
       " ['دفرا', 'SSCL', 'Error: request error!'],\n",
       " ['دفرا', 'SSDL', 'Error: request error!'],\n",
       " ['دفرا', 'BZCL', 'Error: request error!'],\n",
       " ['دقاضی', 'SSCL', 'Error: request error!'],\n",
       " ['دقاضی', 'SSDL', 'Error: request error!'],\n",
       " ['دقاضی', 'BZCL', 'Error: request error!'],\n",
       " ['دقاضی', 'BZDL', 'Error: request error!'],\n",
       " ['دکوثر', 'SSCL', 'Error: request error!'],\n",
       " ['دکوثر', 'BZCL', 'Error: request error!'],\n",
       " ['رمپنا', 'SSCL', 'Error: request error!'],\n",
       " ['رمپنا', 'SSDL', 'Error: request error!'],\n",
       " ['رمپنا', 'BZCL', 'Error: request error!'],\n",
       " ['رکیش', 'SSCL', 'Error: request error!'],\n",
       " ['ریشمک', 'SSCL', 'Error: request error!'],\n",
       " ['ریشمک', 'SSDL', 'Error: request error!'],\n",
       " ['ریشمک', 'BZCL', 'Error: request error!'],\n",
       " ['زنجان', 'SSCL', 'Error: request error!'],\n",
       " ['سبجنو', 'SSCL', 'Error: request error!'],\n",
       " ['سبجنو', 'SSDL', 'Error: request error!'],\n",
       " ['سبجنو', 'BZCL', 'Error: request error!'],\n",
       " ['سبجنو', 'BZDL', 'Error: request error!'],\n",
       " ['سبزوا', 'SSCL', 'Error: request error!'],\n",
       " ['سبزوا', 'SSDL', 'Error: request error!'],\n",
       " ['سبزوا', 'BZCL', 'Error: request error!'],\n",
       " ['ستران', 'SSCL', 'Error: request error!'],\n",
       " ['سجام', 'SSCL', 'Error: request error!'],\n",
       " ['سجام', 'SSDL', 'Error: request error!'],\n",
       " ['سجام', 'BZCL', 'Error: request error!'],\n",
       " ['سخواف', 'SSCL', 'Error: request error!'],\n",
       " ['سخواف', 'SSDL', 'Error: request error!'],\n",
       " ['سخواف', 'BZCL', 'Error: request error!'],\n",
       " ['سدشت', 'SSCL', 'Error: request error!'],\n",
       " ['سدشت', 'SSDL', 'Error: request error!'],\n",
       " ['سدشت', 'BZCL', 'Error: request error!'],\n",
       " ['سدشت', 'BZDL', 'Error: request error!'],\n",
       " ['سشرق', 'SSCL', 'Error: request error!'],\n",
       " ['سمتاز', 'SSCL', 'Error: request error!'],\n",
       " ['سمتاز', 'BZCL', 'Error: request error!'],\n",
       " ['سمگا', 'SSCL', 'Error: request error!'],\n",
       " ['سمگا', 'BZCL', 'Error: request error!'],\n",
       " ['سپاها', 'SSCL', 'Error: request error!'],\n",
       " ['سپاها', 'SSDL', 'Error: request error!'],\n",
       " ['سپاها', 'BZCL', 'Error: request error!'],\n",
       " ['سپاها', 'BZDL', 'Error: request error!'],\n",
       " ['شبریز', 'SSCL', 'Error: request error!'],\n",
       " ['شبریز', 'SSDL', 'Error: request error!'],\n",
       " ['شبریز', 'BZCL', 'Error: request error!'],\n",
       " ['شبندر', 'SSCL', 'Error: request error!'],\n",
       " ['شبندر', 'SSDL', 'Error: request error!'],\n",
       " ['شبندر', 'BZCL', 'Error: request error!'],\n",
       " ['شبندر', 'BZDL', 'Error: request error!'],\n",
       " ['شبهرن', 'SSCL', 'Error: request error!'],\n",
       " ['شتوکا', 'SSCL', 'Error: request error!'],\n",
       " ['شدوص', 'SSCL', 'Error: request error!'],\n",
       " ['شکربن', 'SSCL', 'Error: request error!'],\n",
       " ['فاذر', 'SSCL', 'Error: request error!'],\n",
       " ['فاذر', 'BZCL', 'Error: request error!'],\n",
       " ['فالوم', 'SSCL', 'Error: request error!'],\n",
       " ['فاما', 'SSCL', 'Error: request error!'],\n",
       " ['فخوز', 'SSCL', 'Error: request error!'],\n",
       " ['فرابورس', 'SSCL', 'Error: request error!'],\n",
       " ['فرابورس', 'SSDL', 'Error: request error!'],\n",
       " ['فرابورس', 'BZCL', 'Error: request error!'],\n",
       " ['فلامی', 'SSCL', 'Error: request error!'],\n",
       " ['فلوله', 'SSCL', 'Error: request error!'],\n",
       " ['قجام', 'SSCL', 'Error: request error!'],\n",
       " ['قجام', 'BZCL', 'Error: request error!'],\n",
       " ['قشرین', 'SSCL', 'Error: request error!'],\n",
       " ['قشرین', 'BZCL', 'Error: request error!'],\n",
       " ['قشیر', 'SSCL', 'Error: request error!'],\n",
       " ['قمرو', 'SSCL', 'Error: request error!'],\n",
       " ['قمرو', 'BZCL', 'Error: request error!'],\n",
       " ['قیستو', 'SSCL', 'Error: request error!'],\n",
       " ['قیستو', 'BZCL', 'Error: request error!'],\n",
       " ['لسرما', 'SSCL', 'Error: request error!'],\n",
       " ['لسرما', 'BZCL', 'Error: request error!'],\n",
       " ['لوتوس', 'SSCL', 'Error: request error!'],\n",
       " ['لوتوس', 'SSDL', 'Error: request error!'],\n",
       " ['لوتوس', 'BZCL', 'Error: request error!'],\n",
       " ['لوتوس', 'BZDL', 'Error: request error!'],\n",
       " ['لپارس', 'SSCL', 'Error: request error!'],\n",
       " ['لپارس', 'SSDL', 'Error: request error!'],\n",
       " ['لپارس', 'BZCL', 'Error: request error!'],\n",
       " ['لپیام', 'SSCL', 'Error: request error!'],\n",
       " ['لپیام', 'SSDL', 'Error: request error!'],\n",
       " ['لپیام', 'BZCL', 'Error: request error!'],\n",
       " ['لپیام', 'BZDL', 'Error: request error!'],\n",
       " ['لکما', 'SSCL', 'Error: request error!'],\n",
       " ['لکما', 'BZCL', 'Error: request error!'],\n",
       " ['مارون', 'SSCL', 'Error: request error!'],\n",
       " ['مارون', 'SSDL', 'Error: request error!'],\n",
       " ['مارون', 'BZCL', 'Error: request error!'],\n",
       " ['مارون', 'BZDL', 'Error: request error!'],\n",
       " ['مرقام', 'SSCL', 'Error: request error!'],\n",
       " ['مرقام', 'BZCL', 'Error: request error!'],\n",
       " ['مرقام', 'BZDL', 'Error: request error!'],\n",
       " ['نشار', 'SSCL', 'Error: request error!'],\n",
       " ['نیرو', 'SSCL', 'Error: request error!'],\n",
       " ['نیرو', 'BZCL', 'Error: request error!'],\n",
       " ['واحصا', 'SSCL', 'Error: request error!'],\n",
       " ['واحصا', 'BZCL', 'Error: request error!'],\n",
       " ['وبرق', 'SSCL', 'Error: request error!'],\n",
       " ['وبشهر', 'SSCL', 'Error: request error!'],\n",
       " ['وبهمن', 'SSCL', 'Error: request error!'],\n",
       " ['وبهمن', 'SSDL', 'Error: request error!'],\n",
       " ['وبهمن', 'BZCL', 'Error: request error!'],\n",
       " ['وبهمن', 'BZDL', 'Error: request error!'],\n",
       " ['وبوعلی', 'SSCL', 'Error: request error!'],\n",
       " ['وبوعلی', 'SSDL', 'Error: request error!'],\n",
       " ['وبوعلی', 'BZCL', 'Error: request error!'],\n",
       " ['وتوصا', 'SSCL', 'Error: request error!'],\n",
       " ['وتوکا', 'SSCL', 'Error: request error!'],\n",
       " ['وتوکا', 'SSDL', 'Error: request error!'],\n",
       " ['وتوکا', 'BZCL', 'Error: request error!'],\n",
       " ['ورنا', 'SSCL', 'Error: request error!'],\n",
       " ['ورنا', 'SSDL', 'Error: request error!'],\n",
       " ['ورنا', 'BZCL', 'Error: request error!'],\n",
       " ['وشمال', 'SSCL', 'Error: request error!'],\n",
       " ['وشمال', 'BZCL', 'Error: request error!'],\n",
       " ['ومعادن', 'SSCL', 'Error: request error!'],\n",
       " ['ومعادن', 'SSDL', 'Error: request error!'],\n",
       " ['ومعادن', 'BZCL', 'Error: request error!'],\n",
       " ['ومعادن', 'BZDL', 'Error: request error!'],\n",
       " ['ونفت', 'SSCL', 'Error: request error!'],\n",
       " ['چافست', 'SSCL', 'Error: request error!'],\n",
       " ['چافست', 'SSDL', 'Error: request error!'],\n",
       " ['چافست', 'BZCL', 'Error: request error!'],\n",
       " ['چکارن', 'SSCL', 'Error: request error!'],\n",
       " ['چکارن', 'SSDL', 'Error: request error!'],\n",
       " ['چکارن', 'BZCL', 'Error: request error!'],\n",
       " ['کاذر', 'SSCL', 'Error: request error!'],\n",
       " ['کاذر', 'SSDL', 'Error: request error!'],\n",
       " ['کاذر', 'BZCL', 'Error: request error!'],\n",
       " ['کاذر', 'BZDL', 'Error: request error!'],\n",
       " ['کاما', 'SSCL', 'Error: request error!'],\n",
       " ['کتوکا', 'SSCL', 'Error: request error!'],\n",
       " ['کتوکا', 'SSDL', 'Error: request error!'],\n",
       " ['کتوکا', 'BZCL', 'Error: request error!'],\n",
       " ['کرماشا', 'SSCL', 'Error: request error!'],\n",
       " ['کرمان', 'SSCL', 'Error: request error!'],\n",
       " ['کرمان', 'SSDL', 'Error: request error!'],\n",
       " ['کرمان', 'BZCL', 'Error: request error!'],\n",
       " ['کرمان', 'BZDL', 'Error: request error!'],\n",
       " ['کشرق', 'SSCL', 'Error: request error!'],\n",
       " ['کشرق', 'SSDL', 'Error: request error!'],\n",
       " ['کشرق', 'BZCL', 'Error: request error!'],\n",
       " ['کشرق', 'BZDL', 'Error: request error!'],\n",
       " ['کصدف', 'SSCL', 'Error: request error!'],\n",
       " ['کصدف', 'SSDL', 'Error: request error!'],\n",
       " ['کصدف', 'BZCL', 'Error: request error!'],\n",
       " ['کمنگنز', 'SSCL', 'Error: request error!'],\n",
       " ['کهمدا', 'SSCL', 'Error: request error!'],\n",
       " ['کهمدا', 'BZCL', 'Error: request error!'],\n",
       " ['کورز', 'SSCL', 'Error: request error!'],\n",
       " ['کیمیا', 'SSCL', 'Error: request error!'],\n",
       " ['گکوثر', 'SSCL', 'Error: request error!'],\n",
       " ['گکوثر', 'SSDL', 'Error: request error!'],\n",
       " ['گکوثر', 'BZCL', 'Error: request error!']]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['fatal_error']\n",
    "data['Errors']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
