{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import jdatetime as jd\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import pickle\n",
    "import io\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# import power_index_calculator as px\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Changing Arbic Characters to Persian Characters !\n",
    "## Credit to \"https://github.com/rezakamalifard/Persian/blob/master/persian/persian.py\"\n",
    "import re\n",
    "def convert_ar_characters(input_str):\n",
    "    mapping = {\n",
    "        'ك': 'ک',\n",
    "        'دِ': 'د',\n",
    "        'بِ': 'ب',\n",
    "        'زِ': 'ز',\n",
    "        'ذِ': 'ذ',\n",
    "        'شِ': 'ش',\n",
    "        'سِ': 'س',\n",
    "        'ى': 'ی',\n",
    "        'ي': 'ی'\n",
    "    }\n",
    "    return _multiple_replace(mapping, input_str)\n",
    "\n",
    "def _multiple_replace(mapping, text):\n",
    "    pattern = \"|\".join(map(re.escape, mapping.keys()))\n",
    "    return re.sub(pattern, lambda m: mapping[m.group()], str(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Loading Balancesheet Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to read different file and prepare them\n",
    "def read_blnc_data(file='98.txt',path=r\"C:\\Users\\Mahdi\\OneDrive\\Master Thesis\\Data\"):\n",
    "\n",
    "    os.chdir(path)\n",
    "    with open(file,encoding=\"utf8\") as f:\n",
    "        fileobject = io.StringIO(f.read())\n",
    "\n",
    "    BlncData = pd.read_csv(fileobject, sep='\\t',  lineterminator='\\n', names=None)\n",
    "    \n",
    "    # Selecting Columns\n",
    "    BlncData = BlncData[['نماد', 'سال مالی', 'تاریخ مصوب','جمع دارایی‌های جاری',\n",
    "           'سرمایه گذاری‌ها و سایر دارایی‌ها', 'خالص دارایی‌های ثابت',\n",
    "           'جمع دارایی‌های غیر جاری', 'جمع کل دارایی‌ها', 'جمع بدهی‌های جاری',\n",
    "           'جمع بدهی‌های غیر جاری', 'جمع کل بدهی‌ها', 'سرمایه',\n",
    "           'سود و زیان انباشته', 'اندوخته قانونی',\n",
    "           'جمع حقوق صاحبان سهام در پایان سال مالی',\n",
    "           'جمع کل بدهی‌ها و حقوق صاحبان سهام',\n",
    "           'جمع حقوق صاحبان سهام مصوب (در مجمع عادی)']]\n",
    "    \n",
    "    # renaming columns\n",
    "    BlncData.rename(columns={'نماد':'Symbol','سال مالی':'Fin_year','جمع دارایی‌های جاری':'Tot_current_asset','تاریخ مصوب':'approve_date',\n",
    "                             'خالص دارایی‌های ثابت':'Net_fixed_assed','سرمایه گذاری‌ها و سایر دارایی‌ها':'other_asset',\n",
    "                             'جمع بدهی‌های جاری':'Tot_current_lib','جمع کل دارایی‌ها':'Tot_asset','جمع دارایی‌های غیر جاری':'Tot_uncurrent_asset',\n",
    "                             'سرمایه':'Capital','حقوق عمومی':'Public_rights','جمع کل بدهی‌ها':'Tot_lib','جمع بدهی‌های غیر جاری':'Tot_uncurrent_lib',\n",
    "                             'سایر اندوخته‌ها':'Other_saving','اندوخته قانونی':'Reserved_saving','سود و زیان انباشته':'Comulated_profit_loss',\n",
    "                             'جمع حقوق صاحبان سهام در پایان سال مالی':'Equity_at_year_end','جمع کل بدهی‌ها و حقوق صاحبان سهام':'Debt_Equity',\n",
    "                              'جمع حقوق صاحبان سهام مصوب (در مجمع عادی)':'Debt_Equity_normal'},inplace=True)\n",
    "\n",
    "    # DataOrg.Symbol: convert_ar_characters(x)\n",
    "    Names = BlncData.Symbol.drop_duplicates()\n",
    "    Conv_Names = Names.apply(lambda x : convert_ar_characters(x))\n",
    "    BlncData_Symbol_ArtoFa_dict = dict(zip(Names,Conv_Names))\n",
    "    BlncData['Symbol'] = BlncData.Symbol.map(BlncData_Symbol_ArtoFa_dict)\n",
    "\n",
    "    # Dates\n",
    "    BlncData = BlncData[~pd.isnull(BlncData.Fin_year)]\n",
    "    BlncData.Fin_year = BlncData.Fin_year.apply(lambda x: jd.date(day=int(x[8:10]), month=int(x[5:7]),year=int(x[0:4])))\n",
    "\n",
    "    BlncData = BlncData[~pd.isnull(BlncData.approve_date)]\n",
    "    BlncData.approve_date = BlncData.approve_date.apply(lambda x: jd.date(day=int(x[8:10]), month=int(x[5:7]),year=int(x[0:4])))\n",
    "    \n",
    "    # changing to int\n",
    "    for x in BlncData.columns[3:]:\n",
    "        BlncData = BlncData[~pd.isnull(BlncData[x])]\n",
    "        BlncData[x] = BlncData[x].apply(lambda x: int(x.replace(',','')))\n",
    "        \n",
    "    return(BlncData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "blnc_data = read_blnc_data(file='98.txt')\n",
    "blnc_data['book_value'] = blnc_data.Tot_asset-blnc_data.Tot_lib\n",
    "blnc_data = blnc_data[blnc_data.book_value>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Loading Shareholder Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading DATA\n",
    "os.chdir(r\"C:\\Users\\Mahdi\\OneDrive\\Master Thesis\\Data\")\n",
    "SDATA = pd.read_csv(\"Shareholder97.csv\",index_col=0)\n",
    "\n",
    "# Conver date from string to jdatetime\n",
    "SDATA['True_Date'] = pd.to_datetime(SDATA['True_Date'], format='%Y-%m-%d')\n",
    "G = SDATA.True_Date.drop_duplicates()\n",
    "J = G.apply(lambda x: jd.date.fromgregorian(day=x.day,month=x.month,year=x.year))\n",
    "DataOrg_date_GtoJ_dict = dict(zip(G,J))\n",
    "SDATA['Jalali_Date']=SDATA.True_Date.map(DataOrg_date_GtoJ_dict)\n",
    "\n",
    "SDATA.drop(columns=['High', 'Low', 'Open', 'Last', 'Volume', 'close',\n",
    "       'True_Date', 'year', 'month', 'day', 'Fill_Flag','Unadjusted_close','chnk_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering and keeping symbols that we have data in both datasets\n",
    "sym_list = list(set(blnc_data.Symbol).intersection(set(SDATA.Symbol.drop_duplicates())))\n",
    "SDATA = SDATA[SDATA.Symbol.isin(sym_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Dataframe for saving concentration mearsurs\n",
    "CMdf = SDATA.groupby('Symbol',as_index=False).agg({'Id_tse':'first','percent':'sum','ShareHolder':'count'}).rename(columns={'ShareHolder':'Num_holders','percent':'sum_over1'})\n",
    "CMdf.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Concentration Measures**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Largest Owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = SDATA.groupby('Symbol',as_index=False).agg({'percent':'max'}).rename(columns={'percent':'Largest_Owner'})\n",
    "CMdf = pd.merge(CMdf,temp,left_on='Symbol',right_on='Symbol',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- First/Second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nth_max(data,nth=1,interval=False):\n",
    "    data = data.sort_values(ascending=False)\n",
    "    if interval:\n",
    "        return(np.round(data.iloc[min(nth[0]-1,len(data)-1):min(nth[1],len(data))],2))\n",
    "    else:\n",
    "        return(np.round(data.iloc[min(nth-1,len(data)-1)],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:618: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3936: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n"
     ]
    }
   ],
   "source": [
    "temp = SDATA.groupby('Symbol',as_index=False).agg({'percent':{lambda x: max(x)/nth_max(x,nth=2,interval=False)}}).rename(columns={'percent':'First_Second'})\n",
    "CMdf = pd.merge(CMdf,temp,left_on='Symbol',right_on='Symbol',how='left').rename(columns={('First_Second', '<lambda>'):'First_Second'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- First/Sumtwofour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:618: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3936: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n"
     ]
    }
   ],
   "source": [
    "temp = SDATA.groupby('Symbol',as_index=False).agg({'percent':{lambda x: max(x)/sum(nth_max(x,nth=[2,4],interval=True))}}).rename(columns={'percent':'First_Sumtwofour'})\n",
    "CMdf = pd.merge(CMdf,temp,left_on='Symbol',right_on='Symbol',how='left').rename(columns={('First_Sumtwofour', '<lambda>'):'First_Sumtwofour'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Sumfive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:618: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3936: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n"
     ]
    }
   ],
   "source": [
    "temp = SDATA.groupby('Symbol',as_index=False).agg({'percent':{lambda x: sum(nth_max(x,nth=[1,5],interval=True))/100}}).rename(columns={'percent':'Sumfive'})\n",
    "CMdf = pd.merge(CMdf,temp,left_on='Symbol',right_on='Symbol',how='left').rename(columns={('Sumfive', '<lambda>'):'Sumfive'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- Gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate gini coeficient using Deaton 1997:\n",
    "$$ \\gamma = \\frac{N+1}{N-1} - \\frac{2}{\\mu\\times N\\times(N-1)}\\sum_{i=1}^N{\\rho_ix_i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(data):\n",
    "    data.sort(reverse = True)\n",
    "    N = len(data)\n",
    "    mu = np.mean(data)\n",
    "    ser = [(i+1)*data[i] for i in range(len(data))]\n",
    "    try:\n",
    "        gamma = (N+1)/(N-1)-(2*sum(ser))/(mu*N*(N-1))\n",
    "    except:\n",
    "        gamma = 0\n",
    "    return(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:618: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3936: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n"
     ]
    }
   ],
   "source": [
    "temp = SDATA.groupby('Symbol',as_index=False).agg({'percent':{lambda x: gini(list(x))}}).rename(columns={'percent':'Gini'})\n",
    "CMdf = pd.merge(CMdf,temp,left_on='Symbol',right_on='Symbol',how='left').rename(columns={('Gini', '<lambda>'):'Gini'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6- Herfindhal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:618: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3936: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n"
     ]
    }
   ],
   "source": [
    "temp = SDATA.groupby('Symbol',as_index=False).agg({'percent':{lambda x: sum([(t/100)**2 for t in list(x)])}}).rename(columns={'percent':'Herfindhal'})\n",
    "CMdf = pd.merge(CMdf,temp,left_on='Symbol',right_on='Symbol',how='left').rename(columns={('Herfindhal', '<lambda>'):'Herfindhal'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-Shapley-Shubik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-Banzhaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took about  0.64 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>SHAPLEY-SHUBIK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.25</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.66</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.77</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.28</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WEIGHT SHAPLEY-SHUBIK\n",
       "0   50.25       1.000000\n",
       "1   16.66       0.000000\n",
       "2   15.77       0.000000\n",
       "3    2.28       0.000000"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = SDATA[SDATA.Symbol==sym_list[0]]\n",
    "percent = list(df.percent)\n",
    "percent.sort(reverse=True)\n",
    "\n",
    "prc = [x for x in percent]\n",
    "\n",
    "prc_str = ''\n",
    "for x in prc:\n",
    "    prc_str+=str(x)\n",
    "    prc_str+=' '\n",
    "\n",
    "\n",
    "\n",
    "url = \"https://mywebpages.csv.warwick.ac.uk/cgi-vpi/ssdirect.cgi\"\n",
    "\n",
    "\n",
    "payload = {'numberofplayers': len(df),\n",
    "           'quota': 50.01,\n",
    "           'textarea': prc_str}\n",
    "\n",
    "response = requests.request(\"POST\", url, data = payload)\n",
    "\n",
    "    \n",
    "html_out = response.text.encode('utf8')\n",
    "print('It took about ',np.round(response.elapsed.microseconds/1000000,2), 'seconds')\n",
    "\n",
    "parsed_html = BeautifulSoup(html_out)\n",
    "rows = parsed_html('tr')\n",
    "\n",
    "data = []\n",
    "for row in rows:\n",
    "    if row.th:\n",
    "        cols = row.find_all('th')\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "        data.append([ele for ele in cols if ele]) # Get rid of empty values\n",
    "    else:\n",
    "        cols = row.find_all('td')\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "        data.append([ele for ele in cols if ele]) # Get rid of empty values\n",
    "    \n",
    "    \n",
    "out = pd.DataFrame(data[1:], columns=data[0])\n",
    "out.iloc[:,0] = prc\n",
    "out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL Dict\n",
    "URL={'direct':\"https://mywebpages.csv.warwick.ac.uk/cgi-vpi/ssdirect.cgi\",\n",
    "     'genf':\"https://mywebpages.csv.warwick.ac.uk/cgi-vpi/ssgenf.cgi\",\n",
    "     'mmle':\"https://mywebpages.csv.warwick.ac.uk/cgi-vpi/ssmmle.cgi\",\n",
    "     'ocean':\"https://mywebpages.csv.warwick.ac.uk/cgi-vpi/ssocean.cgi\"}\n",
    "\n",
    "def find_shapley(Symbol,how='direct',quota = 50.01):\n",
    "    \n",
    "    # Finding data of Symbol\n",
    "    df = SDATA[SDATA.Symbol==Symbol]\n",
    "    percent = list(df.percent)\n",
    "    percent.sort(reverse=True)\n",
    "    \n",
    "    \n",
    "    if len(df)==1:\n",
    "        return('Length Error')\n",
    "    \n",
    "    url = URL[how]\n",
    "    \n",
    "    if how=='direct':\n",
    "        prc = percent\n",
    "        prc_str = ''\n",
    "        for x in prc:\n",
    "            prc_str+=str(x)\n",
    "            prc_str+=' '\n",
    "            \n",
    "        payload = {'numberofplayers': len(df),\n",
    "                   'quota': quota,\n",
    "                   'textarea': prc_str}\n",
    "        \n",
    "    elif how=='genf':\n",
    "        prc = [int(x*100)for x in percent]\n",
    "        prc_str = ''\n",
    "        for x in prc:\n",
    "            prc_str+=str(x)\n",
    "            prc_str+=' '\n",
    "            \n",
    "        payload = {'numberofplayers': len(df),\n",
    "                   'quota': int(quota*100),\n",
    "                   'textarea': prc_str}\n",
    "        \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        response = requests.request(\"POST\", url, data = payload)\n",
    "    except:\n",
    "        return('Error:'+str(response.status_code))\n",
    "    \n",
    "    html_out = response.text.encode('utf8')\n",
    "    print('It took about ',np.round(response.elapsed.microseconds/1000000,2), 'seconds')\n",
    "    \n",
    "    parsed_html = BeautifulSoup(html_out)\n",
    "    rows = parsed_html('tr')\n",
    "\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        if row.th:\n",
    "            cols = row.find_all('th')\n",
    "            cols = [ele.text.strip() for ele in cols]\n",
    "            data.append([ele for ele in cols if ele]) # Get rid of empty values\n",
    "        else:\n",
    "            cols = row.find_all('td')\n",
    "            cols = [ele.text.strip() for ele in cols]\n",
    "            data.append([ele for ele in cols if ele]) # Get rid of empty values\n",
    "    \n",
    "    try:\n",
    "        out = pd.DataFrame(data[1:], columns=data[0])\n",
    "        out.iloc[:,0] = prc\n",
    "        return(out)\n",
    "    except:\n",
    "        print('DataFrame Error')\n",
    "        return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Length Error'"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_shapley(sym_list[1],how='direct',quota = 50.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
